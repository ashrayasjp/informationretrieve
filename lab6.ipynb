{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Techniques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    \"Football is the most popular sport in the world\",\n",
    "    \"Basketball and football are team sports\",\n",
    "    \"Artificial intelligence and machine learning are transforming technology\",\n",
    "    \"Python and Java are widely used programming languages\",\n",
    "    \"Pizza and burgers are popular fast food items\",\n",
    "    \"I love cooking pasta and trying new recipes\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Preprocess: lowercase, remove punctuation, tokenize\n",
    "def clean_and_tokenize(text):\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text.lower())\n",
    "    return text.split()\n",
    "\n",
    "tokenized_docs = [clean_and_tokenize(d) for d in docs]\n",
    "\n",
    "\n",
    "vocab = sorted({word for doc in tokenized_docs for word in doc})\n",
    "\n",
    "def to_vector(tokens, vocab):\n",
    "    counts = Counter(tokens)\n",
    "    return np.array([counts.get(word, 0) for word in vocab])\n",
    "\n",
    "vectors = np.vstack([to_vector(doc, vocab) for doc in tokenized_docs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Means Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Means Cluster assignments: [1, 2, 2, 2, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "def k_means(data, k=3, iterations=50):\n",
    "    rng = np.random.default_rng(42)\n",
    "    centers = data[rng.choice(len(data), k, replace=False)]\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        # Assign step\n",
    "        labels = [np.argmin([np.linalg.norm(x-c) for c in centers]) for x in data]\n",
    "        \n",
    "        # Update step\n",
    "        new_centers = np.array([\n",
    "            data[np.array(labels) == i].mean(axis=0) if i in labels else centers[i]\n",
    "            for i in range(k)\n",
    "        ])\n",
    "        \n",
    "        if np.allclose(new_centers, centers):\n",
    "            break\n",
    "        centers = new_centers\n",
    "    \n",
    "    return labels, centers\n",
    "\n",
    "labels_km, centers_km = k_means(vectors, k=3)\n",
    "print(\"K-Means Cluster assignments:\", labels_km)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Medoids Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Medoids Clusters: {0: [5], 1: [0], 2: [1, 2, 3, 4]}\n"
     ]
    }
   ],
   "source": [
    "def k_medoids(data, k=3, max_iter=50):\n",
    "    rng = np.random.default_rng(42)\n",
    "    medoids = rng.choice(len(data), k, replace=False)\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        # Assign points\n",
    "        clusters = {i: [] for i in range(k)}\n",
    "        for idx, x in enumerate(data):\n",
    "            dists = [np.linalg.norm(x - data[m]) for m in medoids]\n",
    "            clusters[np.argmin(dists)].append(idx)\n",
    "        \n",
    "        # Update medoids\n",
    "        new_medoids = []\n",
    "        for i in range(k):\n",
    "            if not clusters[i]:\n",
    "                new_medoids.append(medoids[i])\n",
    "                continue\n",
    "            # find index minimizing total distance\n",
    "            intra_dists = [sum(np.linalg.norm(data[p]-data[q]) for q in clusters[i]) for p in clusters[i]]\n",
    "            new_medoids.append(clusters[i][np.argmin(intra_dists)])\n",
    "        \n",
    "        if np.array_equal(new_medoids, medoids):\n",
    "            break\n",
    "        medoids = new_medoids\n",
    "    \n",
    "    return clusters, medoids\n",
    "\n",
    "clusters_km, medoid_idx = k_medoids(vectors, k=3)\n",
    "print(\"K-Medoids Clusters:\", clusters_km)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Shingling Using Jaccard's Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Similarity Matrix:\n",
      " [[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "def make_shingles(tokens, k=2):\n",
    "    return {tuple(tokens[i:i+k]) for i in range(len(tokens)-k+1)}\n",
    "\n",
    "shingles_list = [make_shingles(doc, k=2) for doc in tokenized_docs]\n",
    "\n",
    "def jaccard(a, b):\n",
    "    return len(a & b) / len(a | b) if a | b else 0\n",
    "\n",
    "sim_matrix = np.array([\n",
    "    [jaccard(shingles_list[i], shingles_list[j]) for j in range(len(shingles_list))]\n",
    "    for i in range(len(shingles_list))\n",
    "])\n",
    "\n",
    "print(\"Jaccard Similarity Matrix:\\n\", np.round(sim_matrix, 2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3196968d684371006099b3d55edeef8ed90365227a30deaef86e5d4aa8519be0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
